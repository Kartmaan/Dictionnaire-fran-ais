{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas dataframe of the dictionary dico.csv\n",
    "df = pd.read_csv(\"dico.csv\")\n",
    "df = df.sort_values(\"Mot\")\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(partial, total, rnd=2):\n",
    "    try:\n",
    "        return round((partial/total)*100, rnd)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_filter(df, col_name, no_comp=True, length=None, start_with=None, \n",
    "end_with=None, nth_letters=None, contains=None, not_contain=None,\n",
    "log=None):\n",
    "\n",
    "    \"\"\" Allows multiple filters to be applied to \n",
    "    dictionary words :\n",
    "    - df = Pandas dataframe of dico.csv\n",
    "    - no_comp = Remove compound words\n",
    "    - length = Word length\n",
    "    - start_with = Letter(s) with which the word must start\n",
    "    - end_with = Letter(s) with which the word must end\n",
    "    - nth_letter = The letter that the word must contain at \n",
    "    rank n. must be an indexable container object, \n",
    "    for example a tuple: (rank, letter) where rank is a \n",
    "    positive integer and letter a str\n",
    "    \"\"\"\n",
    "    # Logging initialisation\n",
    "    if log != None:\n",
    "        log = log.upper()\n",
    "        if log == \"DEBUG\":\n",
    "            logger.setLevel(logging.DEBUG)\n",
    "        elif log == \"INFO\":\n",
    "            logger.setLevel(logging.INFO)\n",
    "        elif log == \"WARNING\":\n",
    "            logger.setLevel(logging.WARNING)\n",
    "        elif log == \"CRITICAL\":\n",
    "            logger.setLevel(logging.CRITICAL)\n",
    "        else:\n",
    "            logger.setLevel(logging.CRITICAL)\n",
    "    else:\n",
    "        logger.setLevel(logging.CRITICAL)\n",
    "    \n",
    "    # Dataframe check\n",
    "    if type(df) != pd.core.frame.DataFrame:\n",
    "        logging.critical(f\"\"\"\n",
    "        df must be a Pandas dataframe. {type(df)} given \"\"\")\n",
    "        return None\n",
    "        \n",
    "    else:\n",
    "        if col_name not in df.columns:\n",
    "            logging.critical(f\"\"\"\n",
    "            '{col_name}' column doesn't exist in the dataframe.\n",
    "            Columns present : {[col for col in df.columns]}\"\"\")\n",
    "            return None\n",
    "    \n",
    "    # contains/not_contain check\n",
    "    if contains != None and not_contain != None:\n",
    "        if set(contains) & set(not_contain):\n",
    "            logging.critical(f\"\"\"\n",
    "            'contains' and 'not_contain' must not share common values  \"\"\")\n",
    "            return None\n",
    "\n",
    "    INIT_TIME = time()\n",
    "    INIT_SHAPE = df.shape[0]\n",
    "    filters_crossed = []\n",
    "\n",
    "    logging.debug(f\"\"\"\n",
    "    -- INITIAL VALUES --\n",
    "    Start at : {INIT_TIME}\n",
    "    Dataframe shape : {df.shape}\n",
    "    Column to filter : {col_name}\n",
    "    no_comp = {no_comp}\n",
    "    length = {length}\n",
    "    start_with = {start_with}\n",
    "    end_with = {end_with}\n",
    "    nth_letters = {nth_letters}\n",
    "    contains = {contains}\n",
    "    not_contain = {not_contain}\n",
    "    \"\"\")\n",
    "\n",
    "    # FILTER 1/ No compound words\n",
    "    if no_comp:\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[\n",
    "        (~df[col_name].str.contains(r'\\s')) & \n",
    "        (~df[col_name].str.contains(r'-'))\n",
    "        ]\n",
    "\n",
    "        end_time = time()\n",
    "        logging.debug(f\"\"\"\n",
    "        -- 'no_comp' FILTER -- \n",
    "        Execution time : {round(end_time-start_time, 3)}s\n",
    "        Rows before : {INIT_SHAPE} \n",
    "        Rows after : {df.shape[0]}\n",
    "        Rows deleted : {INIT_SHAPE - df.shape[0]} \n",
    "        Vario : (-{percent(INIT_SHAPE - df.shape[0], INIT_SHAPE)}%)\n",
    "        \"\"\")\n",
    "        filters_crossed.append(\"no_comp\")\n",
    "    \n",
    "    # FILTER 2/ By word length\n",
    "    if length != None:\n",
    "        if not isinstance(length, int):\n",
    "            raise TypeError(f\"\"\"\n",
    "            'length' must be a int type : ({type(length)} given)\n",
    "            \"\"\")\n",
    "\n",
    "        else:\n",
    "            ponctual_shape = df.shape[0]\n",
    "            start_time = time()\n",
    "\n",
    "            df = df.loc[df[col_name].str.len() == length]\n",
    "\n",
    "            end_time = time()\n",
    "            logging.debug(f\"\"\"\n",
    "            -- 'length' FILTER -- \n",
    "            Execution time : {round(end_time-start_time, 3)}s\n",
    "            Rows before : {ponctual_shape}\n",
    "            Rows after : {df.shape[0]} \n",
    "            Rows deleted : {ponctual_shape - df.shape[0]} \n",
    "            Ponctual vario : (-{percent(ponctual_shape - df.shape[0], ponctual_shape)}%)\n",
    "            Total vario : (-{percent(ponctual_shape - df.shape[0], INIT_SHAPE)}%)\n",
    "            \"\"\")\n",
    "            filters_crossed.append(\"length\")\n",
    "    \n",
    "    # FILTER 3/ By absence of letters\n",
    "    if not_contain != None:\n",
    "        not_contain = set(not_contain)\n",
    "        r = \"\"\n",
    "        for lettre in not_contain:\n",
    "            r = r + f\"(?=.*{lettre})\"\n",
    "\n",
    "        regex = f\"^{r}.*$\"\n",
    "\n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[~df[col_name].str.contains(regex)]\n",
    "\n",
    "        end_time = time()\n",
    "        logging.debug(f\"\"\"\n",
    "        -- 'not_contain' FILTER -- \n",
    "        Execution time : {round(end_time-start_time, 3)}s\n",
    "        Rows before : {ponctual_shape}\n",
    "        Rows after : {df.shape[0]}  \n",
    "        Rows deleted : {ponctual_shape - df.shape[0]}\n",
    "        Ponctual vario : (-{percent(ponctual_shape - df.shape[0], ponctual_shape)}%)\n",
    "        Total vario : (-{percent(ponctual_shape - df.shape[0], INIT_SHAPE)}%)\n",
    "        \"\"\")\n",
    "        filters_crossed.append(\"not_contain\")\n",
    "    \n",
    "    # FILTER 4/ By presence of letters\n",
    "    if contains != None:\n",
    "        contains = set(contains)\n",
    "        r = \"\"\n",
    "        for lettre in contains:\n",
    "            r = r + f\"(?=.*{lettre})\"\n",
    "\n",
    "        regex = f\"^{r}.*$\"\n",
    "\n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[df[col_name].str.contains(regex)]\n",
    "\n",
    "        end_time = time()\n",
    "        logging.debug(f\"\"\"\n",
    "        -- 'contains' FILTER -- \n",
    "        Execution time : {round(end_time-start_time, 3)}s\n",
    "        Rows before : {ponctual_shape}\n",
    "        Rows after : {df.shape[0]}\n",
    "        Rows deleted : {ponctual_shape - df.shape[0]}\n",
    "        Ponctual vario : (-{percent(ponctual_shape - df.shape[0], ponctual_shape)}%)\n",
    "        Total vario : (-{percent(ponctual_shape - df.shape[0], INIT_SHAPE)}%)\n",
    "        \"\"\")\n",
    "        filters_crossed.append(\"contains\")\n",
    "    \n",
    "    # FILTER 5/ By beginning of word\n",
    "    if start_with != None:\n",
    "        if not isinstance(start_with, str):\n",
    "            raise TypeError(f\"\"\"\n",
    "            'start_with' must be a str type : \n",
    "            ({type(start_with)} given)\n",
    "            \"\"\")\n",
    "\n",
    "        else:\n",
    "            start_with = start_with.capitalize()\n",
    "\n",
    "            ponctual_shape = df.shape[0]\n",
    "            start_time = time()\n",
    "\n",
    "            df = df.loc[df[col_name].str.startswith(start_with)]\n",
    "\n",
    "            end_time = time()\n",
    "            logging.debug(f\"\"\"\n",
    "            -- 'start_with' FILTER -- \n",
    "            Execution time : {round(end_time-start_time, 3)}s\n",
    "            Rows before : {ponctual_shape}\n",
    "            Rows after : {df.shape[0]}\n",
    "            Rows deleted : {ponctual_shape - df.shape[0]}\n",
    "            Ponctual vario : (-{percent(ponctual_shape - df.shape[0], ponctual_shape)}%)\n",
    "            Total vario : (-{percent(ponctual_shape - df.shape[0], INIT_SHAPE)}%)\n",
    "            \"\"\")\n",
    "            filters_crossed.append(\"start_with\")\n",
    "    \n",
    "    # FILTER 6/ By letters position\n",
    "    if nth_letters != None:\n",
    "        nth_letters = dict(nth_letters)\n",
    "        \n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        for rank, letter in nth_letters.items():\n",
    "            df = df.loc[df[col_name].apply(lambda x: len(x) > rank and x[rank-1] == letter)]\n",
    "\n",
    "        end_time = time()\n",
    "        logging.debug(f\"\"\"\n",
    "        -- 'nth_letters' FILTER -- \n",
    "        Execution time : {round(end_time-start_time, 3)}s\n",
    "        Rows before : {ponctual_shape}\n",
    "        Rows after : {df.shape[0]}\n",
    "        Rows deleted : {ponctual_shape - df.shape[0]}\n",
    "        Ponctual vario : (-{percent(ponctual_shape - df.shape[0], ponctual_shape)}%)\n",
    "        Total vario : (-{percent(ponctual_shape - df.shape[0], INIT_SHAPE)}%)\n",
    "        \"\"\")\n",
    "        filters_crossed.append(\"nth_letters\")\n",
    "\n",
    "    # FILTER 7/ By ending of word\n",
    "    if end_with != None:\n",
    "        if not isinstance(end_with, str):\n",
    "            raise TypeError(f\"\"\"\n",
    "            'end_with' must be a str type : ({type(end_with)} given)\n",
    "            \"\"\")\n",
    "\n",
    "        else:\n",
    "            ponctual_shape = df.shape[0]\n",
    "            start_time = time()\n",
    "\n",
    "            df = df.loc[df[col_name].str.endswith(end_with)]\n",
    "\n",
    "            end_time = time()\n",
    "            logging.debug(f\"\"\"\n",
    "            -- 'end_with' FILTER -- \n",
    "            Execution time : {round(end_time-start_time, 3)}s\n",
    "            Rows before : {ponctual_shape} \n",
    "            Rows after : {df.shape[0]}\n",
    "            Rows deleted : {ponctual_shape - df.shape[0]}\n",
    "            Ponctual vario : (-{percent(ponctual_shape - df.shape[0], ponctual_shape)}%)\n",
    "            Total vario : (-{percent(ponctual_shape - df.shape[0], INIT_SHAPE)}%)\n",
    "            \"\"\")\n",
    "            filters_crossed.append(\"end_with\")\n",
    "    \n",
    "    logging.debug(f\"\"\"\n",
    "    -- FINAL STATS -- \n",
    "    Filters crossed = {len(filters_crossed)}/7 -> {filters_crossed}\n",
    "    Total execution time : {round(time() - INIT_TIME, 3)}s\n",
    "    Total rows deleted : {INIT_SHAPE - df.shape[0]}\n",
    "    From {INIT_SHAPE} to {df.shape[0]} -> (-{percent(INIT_SHAPE - df.shape[0], INIT_SHAPE)}%)\n",
    "    \"\"\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Définitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>354594</th>\n",
       "      <td>Gardait</td>\n",
       "      <td>['Du verbe garder.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358040</th>\n",
       "      <td>Germait</td>\n",
       "      <td>['Du verbe germer.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358324</th>\n",
       "      <td>Gertait</td>\n",
       "      <td>[\"Troisième personne du singulier de l'indicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358410</th>\n",
       "      <td>Gerçait</td>\n",
       "      <td>['Du verbe gercer.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360323</th>\n",
       "      <td>Givrait</td>\n",
       "      <td>['Du verbe givrer.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364839</th>\n",
       "      <td>Gourait</td>\n",
       "      <td>['Du verbe gourer.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366001</th>\n",
       "      <td>Gradait</td>\n",
       "      <td>[\"Troisième personne du singulier de l'indicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367078</th>\n",
       "      <td>Grandit</td>\n",
       "      <td>['Du verbe grandir.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368175</th>\n",
       "      <td>Gratuit</td>\n",
       "      <td>[\"Qu'on donne, sans y être tenu.\", '…']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368212</th>\n",
       "      <td>Gravait</td>\n",
       "      <td>['Du verbe graver.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369007</th>\n",
       "      <td>Grenait</td>\n",
       "      <td>[\"Troisième personne du singulier de l'indicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369298</th>\n",
       "      <td>Grevait</td>\n",
       "      <td>[\"Troisième personne du singulier de l'indicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369840</th>\n",
       "      <td>Grimait</td>\n",
       "      <td>['Du verbe grimer.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370409</th>\n",
       "      <td>Grisait</td>\n",
       "      <td>['Du verbe griser.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371798</th>\n",
       "      <td>Grutait</td>\n",
       "      <td>[\"Troisième personne du singulier de l'indicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372193</th>\n",
       "      <td>Grésait</td>\n",
       "      <td>[\"Troisième personne du singulier de l'indicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372441</th>\n",
       "      <td>Grêlait</td>\n",
       "      <td>['Du verbe grêler.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mot                                        Définitions\n",
       "354594  Gardait                               ['Du verbe garder.']\n",
       "358040  Germait                               ['Du verbe germer.']\n",
       "358324  Gertait  [\"Troisième personne du singulier de l'indicat...\n",
       "358410  Gerçait                               ['Du verbe gercer.']\n",
       "360323  Givrait                               ['Du verbe givrer.']\n",
       "364839  Gourait                               ['Du verbe gourer.']\n",
       "366001  Gradait  [\"Troisième personne du singulier de l'indicat...\n",
       "367078  Grandit                              ['Du verbe grandir.']\n",
       "368175  Gratuit            [\"Qu'on donne, sans y être tenu.\", '…']\n",
       "368212  Gravait                               ['Du verbe graver.']\n",
       "369007  Grenait  [\"Troisième personne du singulier de l'indicat...\n",
       "369298  Grevait  [\"Troisième personne du singulier de l'indicat...\n",
       "369840  Grimait                               ['Du verbe grimer.']\n",
       "370409  Grisait                               ['Du verbe griser.']\n",
       "371798  Grutait  [\"Troisième personne du singulier de l'indicat...\n",
       "372193  Grésait  [\"Troisième personne du singulier de l'indicat...\n",
       "372441  Grêlait                               ['Du verbe grêler.']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_filter(df,\n",
    "col_name=\"Mot\",\n",
    "start_with=\"g\",\n",
    "end_with=\"it\",\n",
    "contains=[\"a\",\"r\"],\n",
    "not_contain=[\"b\"], \n",
    "length=7\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

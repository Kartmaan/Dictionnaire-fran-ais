{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Analyzer\n",
    "Tool for multi-filtering words in a Pandas dataframe according to specific conditions :\n",
    "\n",
    "- No compound words\n",
    "- N-letter words\n",
    "- Words starting with\n",
    "- Words ending with\n",
    "- Words that must contain such letters\n",
    "- Words that must not contain such letters\n",
    "- Words that must contain such letters at such rank\n",
    "- Words that they are anagrams to the letters present in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the arguments of the multi_filters function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 8 filters of the function are arranged in series. On each passage through an activated filter, the dataframe is transformed (by losing lines according to the desired criteria) until reaching the output of the function.\n",
    "\n",
    "### no_comp \n",
    "**Type** : bool\n",
    "\n",
    "**Default** : `True`\n",
    "\n",
    "Delete compound words (with spaces and dashes) in order to allow the filter to compose only with whole words\n",
    "\n",
    "`multi_filters(df, col_name =\"Mot\", no_comp=True)`\n",
    "\n",
    "### length\n",
    "**Type** : int\n",
    "\n",
    "**Default** : `None`\n",
    "\n",
    "Filter words according to a given length\n",
    "\n",
    "`multi_filters(df, col_name =\"Mot\", length=7)`\n",
    "\n",
    "### start_with\n",
    "**Type** : str\n",
    "\n",
    "**Default** : `None`\n",
    "\n",
    "Filter words starting with one or more letters given in a str\n",
    "\n",
    "`multi_filters(df, col_name =\"Mot\", start_with=\"Per\")`\n",
    "\n",
    "### end_with\n",
    "**Type** : str\n",
    "\n",
    "**Default** : `None`\n",
    "\n",
    "Filter words ending with one or more letters given in a str\n",
    "\n",
    "`multi_filters(df, col_name =\"Mot\", end_with=\"eur\")`\n",
    "\n",
    "### contains\n",
    "**Type** : list\n",
    "\n",
    "**Default** : `None`\n",
    "\n",
    "Filter words according to the letters they must contain\n",
    "\n",
    "`multi_filters(df, col_name =\"Mot\", contains=[\"r\", \"e\", \"t\"])`\n",
    "\n",
    "### not_contain\n",
    "**Type** : list\n",
    "\n",
    "**Default** : `None`\n",
    "\n",
    "Filter words according to the letters they must NOT contain\n",
    "\n",
    "`multi_filters(df, col_name =\"Mot\", not_contain=[\"v\", \"i\", \"m\"])`\n",
    "\n",
    "### nth_letters\n",
    "**Type** : list of lists\n",
    "\n",
    "**Default** : `None`\n",
    "\n",
    "Filters words according to the letters they must contain at specific ranks. Each sub-element must be a list containing `[desired rank (int), desired letter (str)]`\n",
    "\n",
    "`multi_filters(df, col_name =\"Mot\", nth_letters=[[2,\"t\"],[5,\"r\"]])`\n",
    "\n",
    "### anagram\n",
    "**Type** : list\n",
    "\n",
    "**Default** : `None`\n",
    "\n",
    "Filter words so that they are anagrams to the letters present in the list\n",
    "\n",
    "`multi_filters(df, col_name =\"Mot\", anagram=[\"a\", \"s\", \"c\"])`\n",
    "\n",
    "### log\n",
    "**Type** : str\n",
    "\n",
    "**Default** : \"info\"\n",
    "\n",
    "Define the level of logging to display, by default is set to \"info\" which will display messages of this level and higher. In \"debug\" mode, advanced statistics are displayed each time the filter is passed, including the execution time, the number of lines deleted, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import itertools\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas dataframe of the dictionary dico.csv\n",
    "df = pd.read_csv(\"dico.csv\")\n",
    "df = df.sort_values(\"Mot\")\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "INIT_ROWS = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(partial, total, rnd=2):\n",
    "    \"\"\" Calculates the percentage changes of rows deleted \n",
    "    on each filter pass \"\"\"\n",
    "    \n",
    "    try:\n",
    "        return round((partial/total)*100, rnd)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(filter, start_time, end_time, rows_before, rows_after):\n",
    "    \"\"\" Displays debug messages on each filter pass when the 'log' \n",
    "    argument of the 'multi_filters' function is 'debug' \"\"\"\n",
    "    \n",
    "    exec_time = round(end_time-start_time, 3)\n",
    "    rows_del = rows_before - rows_after\n",
    "    relative_vario = percent(rows_before - rows_after, rows_before)\n",
    "    global_vario = percent(INIT_ROWS - rows_after, INIT_ROWS)\n",
    "\n",
    "    logging.debug(f\"\"\"\n",
    "        --- '{filter}' FILTER --- \n",
    "        Execution time : {exec_time}s\n",
    "        Rows before : {rows_before} \n",
    "        Rows after : {rows_after}\n",
    "        Rows deleted : {rows_before - rows_after} \n",
    "        Ponctual vario : (-{relative_vario}%)\n",
    "        Global vario : (-{global_vario}%)\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_filters(df, col_name, no_comp=True, length=None, start_with=None, \n",
    "end_with=None, nth_letters=None, contains=None, not_contain=None, anagram=None,\n",
    "log=\"info\"):\n",
    "\n",
    "    \"\"\" Allows multiple filters to be applied to \n",
    "    dictionary words :\n",
    "\n",
    "    :param df : Pandas dataframe of dico.csv\n",
    "    :type df : pandas.core.frame.DataFrame\n",
    "\n",
    "    :param col_name : column name to filter in dataframe\n",
    "    :type col_name : str\n",
    "\n",
    "    :param no_comp : Remove compound words\n",
    "    :type no_comp : bool\n",
    "\n",
    "    :param length : Word length\n",
    "    :type length : int\n",
    "\n",
    "    :param start_with : Letter(s) with which the word must start\n",
    "    :type start_with : str \n",
    "\n",
    "    :param end_with : Letter(s) with which the word must end\n",
    "    :type end_with : str\n",
    "\n",
    "    :param nth_letter = The letter that the word must contain at rank n.\n",
    "    :type nth_letter : list\n",
    "\n",
    "    :param contains = Letters that the word must contain\n",
    "    :type contains = list\n",
    "\n",
    "    :param not_contain = Letters that the word must NOT contain\n",
    "    :type not_contain = list\n",
    "\n",
    "    :param anagram = Letters composing the anagram\n",
    "    :type not_contain = list\n",
    "\n",
    "    :param log = Enable logging with the desired level (debug, info, warning, critical)\n",
    "    can be set at None in this case only the CRITICAL will be displayed\n",
    "    :type log = str\n",
    "\n",
    "    :param return = Returns a new filtered dataframe\n",
    "    :type return = pandas.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "    # Logging initialisation\n",
    "    if log != None:\n",
    "        log = log.upper()\n",
    "        if log == \"DEBUG\":\n",
    "            logger.setLevel(logging.DEBUG)\n",
    "        elif log == \"INFO\":\n",
    "            logger.setLevel(logging.INFO)\n",
    "        elif log == \"WARNING\":\n",
    "            logger.setLevel(logging.WARNING)\n",
    "        elif log == \"CRITICAL\":\n",
    "            logger.setLevel(logging.CRITICAL)\n",
    "        else:\n",
    "            logger.setLevel(logging.CRITICAL)\n",
    "    else:\n",
    "        logger.setLevel(logging.CRITICAL)\n",
    "    \n",
    "    # ------------ DATAFRAME CHECKS ------------\n",
    "    # Dataframe check\n",
    "    if type(df) != pd.core.frame.DataFrame:\n",
    "        logging.critical(f\"\"\"\n",
    "        df must be a Pandas dataframe. {type(df)} given \"\"\")\n",
    "        return None\n",
    "        \n",
    "    elif col_name not in df.columns:\n",
    "        logging.critical(f\"\"\"\n",
    "        '{col_name}' column doesn't exist in the dataframe.\n",
    "        Columns present : {[col for col in df.columns]}\"\"\")\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # ------------ CONFLICTS CHECK ------------\n",
    "    # contains/not_contain check\n",
    "    if contains != None and not_contain != None:\n",
    "        if not isinstance(contains, list) or not isinstance(not_contain, list):\n",
    "            logging.critical(f\"\"\"'contains' or 'not_contain' isn't a list\"\"\")\n",
    "            return None\n",
    "\n",
    "        elif set(contains) & set(not_contain):\n",
    "            logging.critical(f\"\"\"\n",
    "            'contains' and 'not_contain' must not share common values  \"\"\")\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    INIT_TIME = time()\n",
    "    INIT_SHAPE = df.shape[0]\n",
    "    filters_crossed = []\n",
    "\n",
    "    logging.debug(f\"\"\"\n",
    "    -- INITIAL VALUES --\n",
    "    Start at : {INIT_TIME}\n",
    "    Dataframe shape : {df.shape}\n",
    "    Column to filter : {col_name}\n",
    "    no_comp = {no_comp}\n",
    "    length = {length}\n",
    "    start_with = {start_with}\n",
    "    end_with = {end_with}\n",
    "    nth_letters = {nth_letters}\n",
    "    contains = {contains}\n",
    "    not_contain = {not_contain}\n",
    "    anagram = {anagram}\n",
    "    \"\"\")\n",
    "\n",
    "    # ------------ FILTERS ------------\n",
    "    # FILTER 1/ No compound words\n",
    "    if no_comp:\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[\n",
    "        (~df[col_name].str.contains(r'\\s')) & \n",
    "        (~df[col_name].str.contains(r'-'))\n",
    "        ]\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"no_comp\", start_time, end_time, INIT_SHAPE, df.shape[0])\n",
    "        filters_crossed.append(\"no_comp\")\n",
    "    \n",
    "    # FILTER 2/ By word length\n",
    "    if length != None:\n",
    "        if not isinstance(length, int):\n",
    "            logging.critical(f\"\"\"'length' must be of type int. \n",
    "            {type(length)} given\"\"\")\n",
    "            return None\n",
    "\n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[df[col_name].str.len() == length]\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"length\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "        filters_crossed.append(\"length\")\n",
    "    \n",
    "    # FILTER 3/ By absence of letters\n",
    "    if not_contain != None:\n",
    "        if not isinstance(not_contain, list):\n",
    "            logging.critical(f\"\"\"'not_contain' must be of type list. \n",
    "            {type(not_contain)} given\"\"\")\n",
    "            return None\n",
    "\n",
    "        elif not all(type(x) == str for x in not_contain):\n",
    "            logging.critical(\"\"\"One of the elements of 'not_contain' \n",
    "            is not a str.\"\"\")\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        not_contain = set(not_contain) # remove duplicates\n",
    "        r = \"\"\n",
    "        for lettre in not_contain:\n",
    "            r = r + f\"(?=.*{lettre})\"\n",
    "\n",
    "        regex = f\"^{r}.*$\"\n",
    "\n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[~df[col_name].str.contains(regex)] # ~ for negation\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"not_contain\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "        filters_crossed.append(\"not_contain\")\n",
    "    \n",
    "    # FILTER 4/ By presence of letters\n",
    "    if contains != None:\n",
    "        if not isinstance(contains, list):\n",
    "            logging.critical(f\"\"\"'contains' must be of type list. \n",
    "            {type(contains)} given\"\"\")\n",
    "            return None\n",
    "\n",
    "        elif not all(type(x) == str for x in contains):\n",
    "            logging.critical(\"\"\"One of the elements of 'contains' \n",
    "            is not a str.\"\"\")\n",
    "            return None\n",
    "\n",
    "        contains = set(contains) # remove duplicates\n",
    "        r = \"\"\n",
    "        for lettre in contains:\n",
    "            r = r + f\"(?=.*{lettre})\"\n",
    "\n",
    "        regex = f\"^{r}.*$\"\n",
    "\n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[df[col_name].str.contains(regex)]\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"contains\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "        filters_crossed.append(\"contains\")\n",
    "    \n",
    "    # FILTER 5/ By beginning of word\n",
    "    if start_with != None:\n",
    "        if not isinstance(start_with, str):\n",
    "            logging.critical(f\"\"\"'start_with' must be of type str. \n",
    "            {type(start_with)} given\"\"\")\n",
    "            return None\n",
    "\n",
    "        start_with = start_with.capitalize()\n",
    "\n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[df[col_name].str.startswith(start_with)]\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"start_with\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "        filters_crossed.append(\"start_with\")\n",
    "    \n",
    "    # FILTER 6/ By letters position\n",
    "    if nth_letters != None:\n",
    "        if not isinstance(nth_letters, list):\n",
    "            logging.critical(f\"\"\"'nth_letters' must be of type list. \n",
    "            {type(nth_letters)} given\"\"\")\n",
    "            return None\n",
    "        \n",
    "        elif not all(type(x)==list and len(x)==2 for x in nth_letters):\n",
    "            logging.critical(f\"\"\"All elements of the 'nth letters' list \n",
    "            must be lists of 2 elements: [rank, letter]\"\"\")\n",
    "            return None\n",
    "        \n",
    "        elif not all(type(x[0])==int and type(x[1])==str \n",
    "        and len(x[1])==1 for x in nth_letters):\n",
    "            logging.critical(f\"\"\"Each sub-element of nth_letters must be a list \n",
    "            composed of 2 elements [rank(int), 1 letter (str)]\"\"\")\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        nth_letters = dict(nth_letters)\n",
    "        \n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        for rank, letter in nth_letters.items():\n",
    "            df = df.loc[df[col_name].apply(lambda x: len(x) > rank and x[rank-1] == letter)]\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"nth_letters\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "        filters_crossed.append(\"nth_letters\")\n",
    "\n",
    "    # FILTER 7/ By ending of word\n",
    "    if end_with != None:\n",
    "        if not isinstance(start_with, str):\n",
    "            logging.critical(f\"\"\"'start_with' must be of type str. \n",
    "            {type(start_with)} given\"\"\")\n",
    "            return None\n",
    "\n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[df[col_name].str.endswith(end_with)]\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"end_with\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "        filters_crossed.append(\"end_with\")\n",
    "    \n",
    "    # FILTER 8/ By anagram\n",
    "    if anagram != None:\n",
    "        if not isinstance(anagram, list):\n",
    "            logging.critical(f\"\"\"'anagram' must be of type list. \n",
    "            {type(anagram)} given\"\"\")\n",
    "            return None\n",
    "\n",
    "        elif not all(type(x) == str for x in anagram):\n",
    "            logging.critical(\"\"\"One of the elements of 'anagram' \n",
    "            is not a str.\"\"\")\n",
    "            return None\n",
    "\n",
    "        start_time = time()\n",
    "        ponctual_shape = df.shape[0]\n",
    "\n",
    "        # Anagrams generation\n",
    "        anagrams_dict = {}\n",
    "        number_of_letters = len(anagram)\n",
    "        \n",
    "        \"\"\"\n",
    "        Permutations of the letters present in the 'anagram' \n",
    "        list so as to form words of different lengths \n",
    "        (from length 1 up to a maximum length which is \n",
    "        the total number of letters present in the list). \n",
    "        Anagrams generated for each word length are added \n",
    "        to the 'anagrams_dict' dictionary \"\"\"\n",
    "        for i in range(number_of_letters):\n",
    "            permut = itertools.permutations(anagram, i+1)\n",
    "            anagrams_of_length_i = set()\n",
    "            for word in permut:\n",
    "                word = \"\".join(word)\n",
    "                word = word.capitalize()\n",
    "                anagrams_of_length_i.add(word)\n",
    "            anagrams_dict[i+1] = anagrams_of_length_i\n",
    "\n",
    "        # Anagrams grouping\n",
    "        all_anagrams = [] # all sets\n",
    "        for anag in anagrams_dict.values():\n",
    "            all_anagrams.append(anag)\n",
    "        \n",
    "        # Merging sets\n",
    "        merged_sets = all_anagrams[0]\n",
    "        for set_i in all_anagrams[1:]:\n",
    "            merged_sets.update(set_i)\n",
    "\n",
    "        df = df[df[col_name].isin(merged_sets)]\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"anagram\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "        filters_crossed.append(\"anagram\")\n",
    "    \n",
    "    if df.shape[0] == 0:\n",
    "        logging.info(\"No words found\")\n",
    "    \n",
    "    logging.debug(f\"\"\"\n",
    "    -- FINAL STATS -- \n",
    "    Total execution time : {round(time() - INIT_TIME, 3)}s\n",
    "    Filters crossed = {len(filters_crossed)}/8 -> {filters_crossed}\n",
    "    Total rows deleted : {INIT_SHAPE - df.shape[0]}\n",
    "    From {INIT_SHAPE} to {df.shape[0]} -> (-{percent(INIT_SHAPE - df.shape[0], INIT_SHAPE, rnd=4)}%)\n",
    "    \"\"\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first example with precise filtering :\n",
    "- Filter the \"Mot\" column of the dataframe\n",
    "- Words must start with \"g\"\n",
    "- End with “it”\n",
    "- Contain the letters \"a\" and \"u\"\n",
    "- Do not contain the letter \"b\"\n",
    "- The 4th letter must be a \"b\"\n",
    "- The word must have a length of 7 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Définitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>365395</th>\n",
       "      <td>Goutait</td>\n",
       "      <td>[\"Troisième personne du singulier de l'indicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368175</th>\n",
       "      <td>Gratuit</td>\n",
       "      <td>[\"Qu'on donne, sans y être tenu.\", '…']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371798</th>\n",
       "      <td>Grutait</td>\n",
       "      <td>[\"Troisième personne du singulier de l'indicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mot                                        Définitions\n",
       "365395  Goutait  [\"Troisième personne du singulier de l'indicat...\n",
       "368175  Gratuit            [\"Qu'on donne, sans y être tenu.\", '…']\n",
       "371798  Grutait  [\"Troisième personne du singulier de l'indicat..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_filters(df,\n",
    "col_name=\"Mot\",\n",
    "start_with=\"g\",\n",
    "end_with=\"it\",\n",
    "contains=[\"a\",\"u\"],\n",
    "not_contain=[\"b\"],\n",
    "nth_letters=[[4,\"t\"]],\n",
    "length=7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second example using anagram filtering :\n",
    "- Filter the \"Mot\" column of the dataframe\n",
    "- The words must be anagrams of the letters \"o\", \"o\", \"g\", \"i\", \"l\" and \"r\"\n",
    "- Have a length of 3 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Définitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359709</th>\n",
       "      <td>Giol</td>\n",
       "      <td>[\"Un des noms vulgaires de l'ivraie.\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359856</th>\n",
       "      <td>Girl</td>\n",
       "      <td>['Jeune danseuse de revue.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369667</th>\n",
       "      <td>Gril</td>\n",
       "      <td>[\"Ustensile de cuisine qui est fait de plusieu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433057</th>\n",
       "      <td>Logo</td>\n",
       "      <td>['Logotype, symbole ou emblème qui représente ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433260</th>\n",
       "      <td>Loir</td>\n",
       "      <td>['Petit mammifère de la famille des myoxidés, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mot                                        Définitions\n",
       "359709  Giol             [\"Un des noms vulgaires de l'ivraie.\"]\n",
       "359856  Girl                       ['Jeune danseuse de revue.']\n",
       "369667  Gril  [\"Ustensile de cuisine qui est fait de plusieu...\n",
       "433057  Logo  ['Logotype, symbole ou emblème qui représente ...\n",
       "433260  Loir  ['Petit mammifère de la famille des myoxidés, ..."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_filters(df,\n",
    "col_name=\"Mot\",\n",
    "anagram=[\"o\",\"o\",\"g\",\"i\",\"l\",\"r\"],\n",
    "length=4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

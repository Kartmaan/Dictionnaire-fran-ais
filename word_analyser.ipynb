{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas dataframe of the dictionary dico.csv\n",
    "df = pd.read_csv(\"dico.csv\")\n",
    "df = df.sort_values(\"Mot\")\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "INIT_ROWS = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(partial, total, rnd=2):\n",
    "    try:\n",
    "        return round((partial/total)*100, rnd)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(filter, start_time, end_time, rows_before, rows_after):\n",
    "    exec_time = round(end_time-start_time, 3)\n",
    "    rows_del = rows_before - rows_after\n",
    "    relative_vario = percent(rows_before - rows_after, rows_before)\n",
    "    global_vario = percent(INIT_ROWS - rows_after, INIT_ROWS)\n",
    "\n",
    "    logging.debug(f\"\"\"\n",
    "        --- '{filter}' FILTER --- \n",
    "        Execution time : {exec_time}s\n",
    "        Rows before : {rows_before} \n",
    "        Rows after : {rows_after}\n",
    "        Rows deleted : {rows_before - rows_after} \n",
    "        Ponctual vario : (-{relative_vario}%)\n",
    "        Global vario : (-{global_vario}%)\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_filter(df, col_name, no_comp=True, length=None, start_with=None, \n",
    "end_with=None, nth_letters=None, contains=None, not_contain=None,\n",
    "log=None):\n",
    "\n",
    "    \"\"\" Allows multiple filters to be applied to \n",
    "    dictionary words :\n",
    "    - df = Pandas dataframe of dico.csv\n",
    "    - col_name = column name to filter in dataframe\n",
    "    - no_comp = Remove compound words\n",
    "    - length = Word length\n",
    "    - start_with = Letter(s) with which the word must start\n",
    "    - end_with = Letter(s) with which the word must end\n",
    "    - nth_letter = The letter that the word must contain at \n",
    "    rank n. must be an indexable container object, \n",
    "    for example a tuple: (rank, letter) where rank is a \n",
    "    positive integer and letter a str\n",
    "    \"\"\"\n",
    "    # Logging initialisation\n",
    "    if log != None:\n",
    "        log = log.upper()\n",
    "        if log == \"DEBUG\":\n",
    "            logger.setLevel(logging.DEBUG)\n",
    "        elif log == \"INFO\":\n",
    "            logger.setLevel(logging.INFO)\n",
    "        elif log == \"WARNING\":\n",
    "            logger.setLevel(logging.WARNING)\n",
    "        elif log == \"CRITICAL\":\n",
    "            logger.setLevel(logging.CRITICAL)\n",
    "        else:\n",
    "            logger.setLevel(logging.CRITICAL)\n",
    "    else:\n",
    "        logger.setLevel(logging.CRITICAL)\n",
    "    \n",
    "    # Dataframe check\n",
    "    if type(df) != pd.core.frame.DataFrame:\n",
    "        logging.critical(f\"\"\"\n",
    "        df must be a Pandas dataframe. {type(df)} given \"\"\")\n",
    "        return None\n",
    "        \n",
    "    else:\n",
    "        if col_name not in df.columns:\n",
    "            logging.critical(f\"\"\"\n",
    "            '{col_name}' column doesn't exist in the dataframe.\n",
    "            Columns present : {[col for col in df.columns]}\"\"\")\n",
    "            return None\n",
    "    \n",
    "    # contains/not_contain check\n",
    "    if contains != None and not_contain != None:\n",
    "        if set(contains) & set(not_contain):\n",
    "            logging.critical(f\"\"\"\n",
    "            'contains' and 'not_contain' must not share common values  \"\"\")\n",
    "            return None\n",
    "\n",
    "    INIT_TIME = time()\n",
    "    INIT_SHAPE = df.shape[0]\n",
    "    filters_crossed = []\n",
    "\n",
    "    logging.debug(f\"\"\"\n",
    "    -- INITIAL VALUES --\n",
    "    Start at : {INIT_TIME}\n",
    "    Dataframe shape : {df.shape}\n",
    "    Column to filter : {col_name}\n",
    "    no_comp = {no_comp}\n",
    "    length = {length}\n",
    "    start_with = {start_with}\n",
    "    end_with = {end_with}\n",
    "    nth_letters = {nth_letters}\n",
    "    contains = {contains}\n",
    "    not_contain = {not_contain}\n",
    "    \"\"\")\n",
    "\n",
    "    # ------------ FILTERS ------------\n",
    "    # FILTER 1/ No compound words\n",
    "    if no_comp:\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[\n",
    "        (~df[col_name].str.contains(r'\\s')) & \n",
    "        (~df[col_name].str.contains(r'-'))\n",
    "        ]\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"no_comp\", start_time, end_time, INIT_SHAPE, df.shape[0])\n",
    "        filters_crossed.append(\"no_comp\")\n",
    "    \n",
    "    # FILTER 2/ By word length\n",
    "    if length != None:\n",
    "        if not isinstance(length, int):\n",
    "            raise TypeError(f\"\"\"\n",
    "            'length' must be a int type : ({type(length)} given)\n",
    "            \"\"\")\n",
    "\n",
    "        else:\n",
    "            ponctual_shape = df.shape[0]\n",
    "            start_time = time()\n",
    "\n",
    "            df = df.loc[df[col_name].str.len() == length]\n",
    "\n",
    "            end_time = time()\n",
    "            debug(\"length\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "            filters_crossed.append(\"length\")\n",
    "    \n",
    "    # FILTER 3/ By absence of letters\n",
    "    if not_contain != None:\n",
    "        not_contain = set(not_contain)\n",
    "        r = \"\"\n",
    "        for lettre in not_contain:\n",
    "            r = r + f\"(?=.*{lettre})\"\n",
    "\n",
    "        regex = f\"^{r}.*$\"\n",
    "\n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[~df[col_name].str.contains(regex)]\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"not_contain\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "        filters_crossed.append(\"not_contain\")\n",
    "    \n",
    "    # FILTER 4/ By presence of letters\n",
    "    if contains != None:\n",
    "        contains = set(contains)\n",
    "        r = \"\"\n",
    "        for lettre in contains:\n",
    "            r = r + f\"(?=.*{lettre})\"\n",
    "\n",
    "        regex = f\"^{r}.*$\"\n",
    "\n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        df = df.loc[df[col_name].str.contains(regex)]\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"contains\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "        filters_crossed.append(\"contains\")\n",
    "    \n",
    "    # FILTER 5/ By beginning of word\n",
    "    if start_with != None:\n",
    "        if not isinstance(start_with, str):\n",
    "            raise TypeError(f\"\"\"\n",
    "            'start_with' must be a str type : \n",
    "            ({type(start_with)} given)\n",
    "            \"\"\")\n",
    "\n",
    "        else:\n",
    "            start_with = start_with.capitalize()\n",
    "\n",
    "            ponctual_shape = df.shape[0]\n",
    "            start_time = time()\n",
    "\n",
    "            df = df.loc[df[col_name].str.startswith(start_with)]\n",
    "\n",
    "            end_time = time()\n",
    "            debug(\"start_with\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "            filters_crossed.append(\"start_with\")\n",
    "    \n",
    "    # FILTER 6/ By letters position\n",
    "    if nth_letters != None:\n",
    "        nth_letters = dict(nth_letters)\n",
    "        \n",
    "        ponctual_shape = df.shape[0]\n",
    "        start_time = time()\n",
    "\n",
    "        for rank, letter in nth_letters.items():\n",
    "            df = df.loc[df[col_name].apply(lambda x: len(x) > rank and x[rank-1] == letter)]\n",
    "\n",
    "        end_time = time()\n",
    "        debug(\"nth_letters\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "        filters_crossed.append(\"nth_letters\")\n",
    "\n",
    "    # FILTER 7/ By ending of word\n",
    "    if end_with != None:\n",
    "        if not isinstance(end_with, str):\n",
    "            raise TypeError(f\"\"\"\n",
    "            'end_with' must be a str type : ({type(end_with)} given)\n",
    "            \"\"\")\n",
    "\n",
    "        else:\n",
    "            ponctual_shape = df.shape[0]\n",
    "            start_time = time()\n",
    "\n",
    "            df = df.loc[df[col_name].str.endswith(end_with)]\n",
    "\n",
    "            end_time = time()\n",
    "            debug(\"end_with\", start_time, end_time, ponctual_shape, df.shape[0])\n",
    "            filters_crossed.append(\"end_with\")\n",
    "    \n",
    "    logging.debug(f\"\"\"\n",
    "    -- FINAL STATS -- \n",
    "    Total execution time : {round(time() - INIT_TIME, 3)}s\n",
    "    Filters crossed = {len(filters_crossed)}/7 -> {filters_crossed}\n",
    "    Total rows deleted : {INIT_SHAPE - df.shape[0]}\n",
    "    From {INIT_SHAPE} to {df.shape[0]} -> (-{percent(INIT_SHAPE - df.shape[0], INIT_SHAPE, rnd=4)}%)\n",
    "    \"\"\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mot</th>\n",
       "      <th>Définitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358324</th>\n",
       "      <td>Gertait</td>\n",
       "      <td>[\"Troisième personne du singulier de l'indicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368175</th>\n",
       "      <td>Gratuit</td>\n",
       "      <td>[\"Qu'on donne, sans y être tenu.\", '…']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371798</th>\n",
       "      <td>Grutait</td>\n",
       "      <td>[\"Troisième personne du singulier de l'indicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mot                                        Définitions\n",
       "358324  Gertait  [\"Troisième personne du singulier de l'indicat...\n",
       "368175  Gratuit            [\"Qu'on donne, sans y être tenu.\", '…']\n",
       "371798  Grutait  [\"Troisième personne du singulier de l'indicat..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_filter(df,\n",
    "col_name=\"Mot\",\n",
    "start_with=\"g\",\n",
    "end_with=\"it\",\n",
    "contains=[\"a\",\"r\"],\n",
    "not_contain=[\"b\"],\n",
    "nth_letters=[[4,\"t\"]],\n",
    "length=7,\n",
    "log=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
